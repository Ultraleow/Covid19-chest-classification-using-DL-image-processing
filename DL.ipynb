{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a20bf9d967ed4850bda94318f12e15ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7a23347d29164b14a43fd1274b427416",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c99ebbc9fdfc4ba8b22ff74c5f50f31c",
              "IPY_MODEL_062434c10c4146028042b97c9b15b1c2"
            ]
          }
        },
        "7a23347d29164b14a43fd1274b427416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c99ebbc9fdfc4ba8b22ff74c5f50f31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_607256056fdf4ddbb23560583a2710a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdee08cdbd794dcfb7ce3be563779ffb"
          }
        },
        "062434c10c4146028042b97c9b15b1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_abcd90f70d014bc691e0bdf8e86d851b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 31966980.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53bce74cce464227ae93f40134a5e55c"
          }
        },
        "607256056fdf4ddbb23560583a2710a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdee08cdbd794dcfb7ce3be563779ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abcd90f70d014bc691e0bdf8e86d851b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53bce74cce464227ae93f40134a5e55c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AKaMCRbNpaY"
      },
      "source": [
        "!pip install alexnet_pytorch\r\n",
        "from alexnet_pytorch import AlexNet\r\n",
        "import json\r\n",
        "import torch\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from PIL import Image\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import time\r\n",
        "# Run this cell to mount your Google Drive.\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "import sys\r\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/image_pro')\r\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/image_pro"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryrPybneN5r1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3aca865-0973-451a-d749-f8c910a84b03"
      },
      "source": [
        "# define model parameters\r\n",
        "NUM_EPOCHS = 20 \r\n",
        "BATCH_SIZE = 64\r\n",
        "MOMENTUM = 0.9\r\n",
        "LR_DECAY = 0.0005\r\n",
        "LR_INIT = 0.01\r\n",
        "IMAGE_DIM = 227  # pixels\r\n",
        "NUM_CLASSES = 2  #number of bit\r\n",
        "DEVICE_IDS = [0, 1, 2, 3]  # GPUs to use\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "model = AlexNet.from_pretrained('alexnet',num_classes=2).to(device)\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# modify this to point to your data directory\r\n",
        "ROOT = r'/content/drive/MyDrive/Colab Notebooks/image_pro/'\r\n",
        "#INPUT_ROOT_DIR = 'alexnet_data_in'\r\n",
        "TRAIN_IMG_DIR = ROOT+'datasets_post/train'\r\n",
        "TEST_IMG_DIR = ROOT+'datasets_post/test'\r\n",
        "VALI_IMG_DIR = ROOT+'datasets_post/vali'\r\n",
        "OUTPUT_DIR = ROOT+'result'\r\n",
        "\r\n",
        "LOG_DIR = OUTPUT_DIR + '/tblogs'  # tensorboard logs\r\n",
        "CHECKPOINT_DIR = OUTPUT_DIR + '/models'  # model checkpoints"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for alexnet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFMDnO_sN683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2678bd68-f179-420d-9ba1-e4b40ad27ef1"
      },
      "source": [
        "# print the seed value\r\n",
        "seed = torch.initial_seed()\r\n",
        "print('Used seed : {}'.format(seed))\r\n",
        "#tbwriter = SummaryWriter(log_dir=LOG_DIR)\r\n",
        "#print('TensorboardX summary writer created')\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Used seed : 13261012814533261490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdbaji35OJ-T"
      },
      "source": [
        "means=[0.485, 0.456, 0.406]\r\n",
        "stds=[0.229, 0.224, 0.225]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV-hT9JqOAav",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "a20bf9d967ed4850bda94318f12e15ba",
            "7a23347d29164b14a43fd1274b427416",
            "c99ebbc9fdfc4ba8b22ff74c5f50f31c",
            "062434c10c4146028042b97c9b15b1c2",
            "607256056fdf4ddbb23560583a2710a8",
            "fdee08cdbd794dcfb7ce3be563779ffb",
            "abcd90f70d014bc691e0bdf8e86d851b",
            "53bce74cce464227ae93f40134a5e55c"
          ]
        },
        "outputId": "6909732b-612b-430a-ee64-65dffc97ce17"
      },
      "source": [
        "ROOT = '.data'\r\n",
        "train_data = datasets.CIFAR10(root = ROOT, \r\n",
        "                             train = True, \r\n",
        "                             download = True)\r\n",
        "\r\n",
        "means = train_data.data.mean(axis = (0,1,2)) / 255\r\n",
        "stds = train_data.data.std(axis = (0,1,2)) / 255"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to .data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a20bf9d967ed4850bda94318f12e15ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting .data/cifar-10-python.tar.gz to .data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "585odnS7OMkF"
      },
      "source": [
        "train_transforms = transforms.Compose([\r\n",
        "                                       transforms.Resize(800),\r\n",
        "                           transforms.RandomRotation(5),\r\n",
        "                           transforms.RandomHorizontalFlip(0.5),\r\n",
        "                          #  transforms.RandomCrop(32, padding = 2),\r\n",
        "                           transforms.ToTensor(),\r\n",
        "                           transforms.Normalize(mean = means, \r\n",
        "                                                std = stds)\r\n",
        "                       ])\r\n",
        "test_transforms = transforms.Compose([\r\n",
        "                                      transforms.Resize(800),\r\n",
        "                           transforms.ToTensor(),\r\n",
        "                           transforms.Normalize(mean = means, \r\n",
        "                                                std = stds)\r\n",
        "                       ])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im_3K-yIOQ5W"
      },
      "source": [
        "def fetchData():\r\n",
        "    '''\r\n",
        "    fetch data from file.\r\n",
        "    @return: train, test and valid dataset\r\n",
        "    '''\r\n",
        "    train_path = TRAIN_IMG_DIR # edit me\r\n",
        "    valid_path = VALI_IMG_DIR # edit me\r\n",
        "    test_path = TRAIN_IMG_DIR\r\n",
        "    train_data = datasets.ImageFolder(train_path, transform=train_transforms)\r\n",
        "    valid_data = datasets.ImageFolder(valid_path, transform=test_transforms)\r\n",
        "    test_data = datasets.ImageFolder(train_path, transform=test_transforms)\r\n",
        "    return train_data, valid_data, test_data\r\n",
        "    #return train_data,test_path\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "train_data,valid_data,test_data = fetchData()\r\n",
        "params = {'batch_size': BATCH_SIZE,\r\n",
        "          'shuffle': True,\r\n",
        "          'num_workers': len(DEVICE_IDS)}\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_data, **params)\r\n",
        "vali_loader = torch.utils.data.DataLoader(valid_data,**params)\r\n",
        "test_loader = torch.utils.data.DataLoader(test_data,**params)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjVSNP_jOVjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7acb7719-43d7-4aa8-9976-198317d4e154"
      },
      "source": [
        "optimizer = optim.Adam(params=model.parameters(), lr=0.0001, weight_decay=5e-4)\r\n",
        "# multiply LR by 1 / 10 after every 30 epochs\r\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\r\n",
        "print('LR Scheduler created')\r\n",
        "# start training!!\r\n",
        "print('Starting training...')\r\n",
        "total_steps = 1\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "criterion = criterion.to(device)\r\n",
        "\r\n",
        "def save_model(model, filename):\r\n",
        "    filename = os.path.join(\"checkpoints\", filename + \".pth\")\r\n",
        "    dirname = os.path.dirname(filename)\r\n",
        "    os.makedirs(dirname, exist_ok=True)\r\n",
        "    torch.save(model.state_dict(), filename)\r\n",
        "def calculate_accuracy(y_pred, y):\r\n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\r\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\r\n",
        "    acc = correct.float() / y.shape[0]\r\n",
        "    return acc\r\n",
        "\r\n",
        "def train(model, iterator, optimizer, criterion, device):\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    for (x, y) in iterator:\r\n",
        "        \r\n",
        "        x = x.to(device)\r\n",
        "        y = y.to(device)\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "                \r\n",
        "        y_pred = model(x)\r\n",
        "        \r\n",
        "        loss = criterion(y_pred, y)\r\n",
        "        \r\n",
        "        acc = calculate_accuracy(y_pred, y)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\r\n",
        "\r\n",
        "def evaluate(model, iterator, criterion, device):\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        \r\n",
        "        for (x, y) in iterator:\r\n",
        "\r\n",
        "            x = x.to(device)\r\n",
        "            y = y.to(device)\r\n",
        "\r\n",
        "            y_pred = model(x)\r\n",
        "\r\n",
        "            loss = criterion(y_pred, y)\r\n",
        "\r\n",
        "            acc = calculate_accuracy(y_pred, y)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "            epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\r\n",
        "\r\n",
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs\r\n",
        "\r\n",
        "best_valid_loss = float('inf')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR Scheduler created\n",
            "Starting training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P45FKMsgOXVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad2ef91-f510-4073-9004-fa67aa58256d"
      },
      "source": [
        "for epoch in range(NUM_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.monotonic()\r\n",
        "    \r\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\r\n",
        "    valid_loss, valid_acc = evaluate(model, vali_loader, criterion, device)\r\n",
        "        \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\r\n",
        "\r\n",
        "    end_time = time.monotonic()\r\n",
        "\r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.427 | Train Acc: 81.55%\n",
            "\t Val. Loss: 1.346 |  Val. Acc: 50.51%\n",
            "Epoch: 02 | Epoch Time: 0m 24s\n",
            "\tTrain Loss: 0.266 | Train Acc: 88.59%\n",
            "\t Val. Loss: 1.248 |  Val. Acc: 48.52%\n",
            "Epoch: 03 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.206 | Train Acc: 91.89%\n",
            "\t Val. Loss: 1.193 |  Val. Acc: 49.22%\n",
            "Epoch: 04 | Epoch Time: 0m 23s\n",
            "\tTrain Loss: 0.186 | Train Acc: 92.03%\n",
            "\t Val. Loss: 1.834 |  Val. Acc: 49.53%\n",
            "Epoch: 05 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.136 | Train Acc: 94.55%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 48.32%\n",
            "Epoch: 06 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.110 | Train Acc: 95.60%\n",
            "\t Val. Loss: 2.018 |  Val. Acc: 48.36%\n",
            "Epoch: 07 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.094 | Train Acc: 96.45%\n",
            "\t Val. Loss: 2.035 |  Val. Acc: 47.93%\n",
            "Epoch: 08 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.078 | Train Acc: 97.47%\n",
            "\t Val. Loss: 3.750 |  Val. Acc: 51.13%\n",
            "Epoch: 09 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.112 | Train Acc: 95.77%\n",
            "\t Val. Loss: 2.009 |  Val. Acc: 48.60%\n",
            "Epoch: 10 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.132 | Train Acc: 94.81%\n",
            "\t Val. Loss: 2.258 |  Val. Acc: 47.10%\n",
            "Epoch: 11 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.057 | Train Acc: 97.76%\n",
            "\t Val. Loss: 2.818 |  Val. Acc: 47.97%\n",
            "Epoch: 12 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.052 | Train Acc: 97.73%\n",
            "\t Val. Loss: 3.026 |  Val. Acc: 47.18%\n",
            "Epoch: 13 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.037 | Train Acc: 98.86%\n",
            "\t Val. Loss: 4.544 |  Val. Acc: 50.98%\n",
            "Epoch: 14 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.43%\n",
            "\t Val. Loss: 5.391 |  Val. Acc: 51.13%\n",
            "Epoch: 15 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.027 | Train Acc: 99.15%\n",
            "\t Val. Loss: 4.636 |  Val. Acc: 48.28%\n",
            "Epoch: 16 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.012 | Train Acc: 99.72%\n",
            "\t Val. Loss: 5.122 |  Val. Acc: 48.64%\n",
            "Epoch: 17 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.021 | Train Acc: 99.29%\n",
            "\t Val. Loss: 4.378 |  Val. Acc: 48.01%\n",
            "Epoch: 18 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.012 | Train Acc: 99.57%\n",
            "\t Val. Loss: 5.823 |  Val. Acc: 50.82%\n",
            "Epoch: 19 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.006 | Train Acc: 99.86%\n",
            "\t Val. Loss: 5.528 |  Val. Acc: 50.16%\n",
            "Epoch: 20 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.57%\n",
            "\t Val. Loss: 4.825 |  Val. Acc: 47.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqayz_NTBv6i"
      },
      "source": [
        "torch.save(model,'/content/drive/MyDrive/Colab Notebooks/image_pro/test_1.pt')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr2jatupBBGg",
        "outputId": "da261c1d-1ca2-408b-a4a2-2a96273975bf"
      },
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\r\n",
        "\r\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\r\n",
        "\r\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.191 | Test Acc: 90.15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qsUaNLQBCdI"
      },
      "source": [
        "def get_predictions(model, iterator, device):\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    images = []\r\n",
        "    labels = []\r\n",
        "    probs = []\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "\r\n",
        "        for (x, y) in iterator:\r\n",
        "\r\n",
        "            x = x.to(device)\r\n",
        "\r\n",
        "            y_pred, _ = model(x)\r\n",
        "\r\n",
        "            y_prob = F.softmax(y_pred, dim = -1)\r\n",
        "            top_pred = y_prob.argmax(1, keepdim = True)\r\n",
        "\r\n",
        "            images.append(x.cpu())\r\n",
        "            labels.append(y.cpu())\r\n",
        "            probs.append(y_prob.cpu())\r\n",
        "\r\n",
        "    images = torch.cat(images, dim = 0)\r\n",
        "    labels = torch.cat(labels, dim = 0)\r\n",
        "    probs = torch.cat(probs, dim = 0)\r\n",
        "\r\n",
        "    return images, labels, probs\r\n",
        "images, labels, probs = get_predictions(model, test_iterator, device)\r\n",
        "pred_labels = torch.argmax(probs, 1)\r\n",
        "def plot_confusion_matrix(labels, pred_labels, classes):\r\n",
        "    \r\n",
        "    fig = plt.figure(figsize = (10, 10));\r\n",
        "    ax = fig.add_subplot(1, 1, 1);\r\n",
        "    cm = confusion_matrix(labels, pred_labels);\r\n",
        "    cm = ConfusionMatrixDisplay(cm, display_labels = classes);\r\n",
        "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\r\n",
        "    plt.xticks(rotation = 20)\r\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKq6k9wLBg9u"
      },
      "source": [
        "https://github.com/bentrevett/pytorch-image-classification/blob/master/3_alexnet.ipynb"
      ]
    }
  ]
}